# ğŸš€ SignalHub Pipeline Logging System

## ğŸ“‹ What You'll See in the Logs

When you upload a file through the SignalHub pipeline, you'll now get **detailed JSON logs** saved to `logs/pipeline_logs/` that show exactly what happened at each step.

## ğŸ” **Step-by-Step Execution Logging**

### **Step 1: Upload & Validation**
```
ğŸ“‹ SUBSTEP 1.1: File Validation
âœ… File validation passed: {file_info}
ğŸ’¾ SUBSTEP 1.2: Saving file to disk  
âœ… File saved to: /path/to/file.wav
ğŸ—„ï¸ SUBSTEP 1.3: Creating database record
âœ… Database record created: {call_id}
ğŸ”„ SUBSTEP 1.4: Updating call status
âœ… Call status updated to 'uploaded'
```

### **Step 2: Audio Processing**
```
ğŸ”„ STEP 2: Starting AUDIO PROCESSING
âœ… Audio processing completed
```

### **Step 3: Transcription**
```
ğŸ”„ STEP 3: Starting TRANSCRIPTION
âœ… Transcription completed
```

### **Step 4: NLP Analysis**
```
ğŸ”„ STEP 4: Starting NLP ANALYSIS
âœ… NLP analysis completed
```

### **Step 5: Database Storage**
```
ğŸ”„ STEP 5: Starting DATABASE STORAGE
âœ… Database storage completed
```

## ğŸ“Š **What Gets Logged**

### **File Operations**
- Original filename and size
- Where file is saved on disk
- File validation results
- File processing status

### **Database Operations**
- What data is inserted into which tables
- Success/failure of each operation
- Exact data being stored

### **Timing Information**
- When each step started and completed
- Duration of each step
- Total pipeline execution time

### **Error Tracking**
- What went wrong and where
- Error details and context
- Failed operations

## ğŸ“ **Log File Structure**

Each pipeline execution creates a JSON file like:
```
logs/pipeline_logs/pipeline_{call_id}_{timestamp}.json
```

Example: `pipeline_abc123-def456_20250903_212553.json`

## ğŸ”§ **How to Use the Logs**

### **1. Find Your Upload**
- Look for the `call_id` from your upload response
- Find the corresponding log file

### **2. Analyze the Execution**
- See exactly which steps succeeded/failed
- Check timing of each operation
- Verify what data was stored

### **3. Debug Issues**
- Identify where things went wrong
- See what data was processed
- Check database operations

## ğŸ’¡ **Example Log Output**

```json
{
  "pipeline_id": "abc123-def456",
  "event": "pipeline_started",
  "timestamp": "2025-09-03T21:25:53.665835",
  "file_info": {
    "filename": "audio.wav",
    "content_type": "audio/wav", 
    "size": 1024000,
    "upload_timestamp": "2025-09-03T21:25:53.665818"
  },
  "steps": [
    {
      "step_name": "upload",
      "event": "step_started",
      "timestamp": "2025-09-03T21:25:53.666536",
      "step_data": {
        "filename": "audio.wav",
        "content_type": "audio/wav",
        "file_size": 1024000
      }
    },
    {
      "step_name": "upload", 
      "substep_name": "file_validation",
      "event": "substep_executed",
      "timestamp": "2025-09-03T21:25:53.668347",
      "substep_data": {
        "filename": "audio.wav",
        "validation_start": "2025-09-03T21:25:53.668291"
      }
    }
    // ... more steps
  ]
}
```

## ğŸ¯ **Benefits**

1. **Complete Visibility**: See every step of the pipeline
2. **Easy Debugging**: Know exactly where issues occur
3. **Performance Analysis**: Track timing of each operation
4. **Data Verification**: Confirm what gets stored in database
5. **Audit Trail**: Keep records of all processing

## ğŸš€ **Next Steps**

1. **Upload a file** through the frontend
2. **Check the logs** in `logs/pipeline_logs/`
3. **Analyze the execution** step by step
4. **Identify any issues** or bottlenecks

The logging system will show you exactly what's working and what's not, making it much easier to debug the duration calculation issue!

